from fastapi import APIRouter, Depends, HTTPException
from sqlalchemy.orm import Session
from app.core.database import get_db
from app.auth.dependencies import verify_protected_token
from app.services.simple_openai import SimpleOpenAIService, OpenAIConversationResponse, OpenAICoachingResponse, WordUsageStatus
from app.services.redis_service import RedisService
from app.services.vocabulary_tier_service import VocabularyTierService
from app.services.suggestion_service import SuggestionService
from app.models.vocabulary import VocabularySuggestion
from app.models.conversation_v2 import Conversation
from pydantic import BaseModel
from typing import List, Dict, Optional
from datetime import datetime
import uuid
import re

router = APIRouter()

class ConversationRequest(BaseModel):
    message: str
    session_id: Optional[int] = None
    personality: Optional[str] = None  # will default from session if not provided
    target_vocabulary: Optional[List[Dict]] = []
    session_type: str = "daily"
    topic: Optional[str] = ""
    last_ai_reply: Optional[str] = None

class ConversationResponse(BaseModel):
    response: str
    feedback: Dict
    vocabulary_tier: Optional[Dict] = None
    usage_analysis: Optional[Dict] = None
    suggestion: Optional[Dict] = None
    used_suggestion_id: Optional[str] = None
    success: bool = True

# Helper function to get or create user from Auth0 token
def get_or_create_user(db: Session, auth0_user: Dict) -> int:
    """Get or create user from Auth0 claims and return user_id"""
    from app.models.user import User
    
    auth0_sub = auth0_user.get("sub")
    email = auth0_user.get("email")
    
    if not auth0_sub:
        raise HTTPException(status_code=400, detail="Auth0 subject not found in token")
    
    # Look for existing user by auth0_sub
    user = db.query(User).filter(User.auth0_sub == auth0_sub).first()
    
    if not user:
        # Create new authenticated user
        user = User(
            auth0_sub=auth0_sub,
            email=email,
            is_anonymous=False,
            is_active=True
        )
        db.add(user)
        db.commit()
        db.refresh(user)
        print(f"âœ… Created new user for Auth0 sub: {auth0_sub}")
    
    return user.id

def get_most_recent_shown_suggestion(db: Session, user_id: str) -> Optional[VocabularySuggestion]:
    """Get the most recent 'shown' suggestion for the user"""
    return db.query(VocabularySuggestion).filter(
        VocabularySuggestion.user_id == user_id,
        VocabularySuggestion.status == "shown"
    ).order_by(VocabularySuggestion.created_at.desc()).first()

def detect_word_usage(corrected_transcript: str, suggested_word: str) -> bool:
    """
    Detect if the suggested word is used in the corrected transcript.
    
    Implements case-insensitive matching with word boundaries and plural handling.
    Uses regex to avoid partial matches (e.g., "run" in "running").
    
    Args:
        corrected_transcript: The corrected transcript text to search
        suggested_word: The word to look for
        
    Returns:
        bool: True if word is found with proper word boundaries
        
    Examples:
        >>> detect_word_usage("I want to elaborate on this", "elaborate")
        True
        >>> detect_word_usage("I want to elaborate on this", "labor")  # partial match
        False
        >>> detect_word_usage("Multiple books on shelves", "book")  # plural
        True
    """
    if not corrected_transcript or not suggested_word:
        return False
    
    # Normalize both text and word for comparison
    normalized_transcript = corrected_transcript.lower().strip()
    normalized_word = suggested_word.lower().strip()
    
    # Create word boundary pattern to avoid partial matches
    # This ensures "run" doesn't match in "running" but does match in "I run daily"
    word_pattern = r'\b' + re.escape(normalized_word) + r'\b'
    
    # Also check for common plural forms (word + s)
    # This handles most English plurals: book->books, cat->cats
    plural_pattern = r'\b' + re.escape(normalized_word) + r's\b'
    
    return bool(re.search(word_pattern, normalized_transcript) or 
                re.search(plural_pattern, normalized_transcript))

# Main endpoint that frontend expects: POST /api/conversation
@router.post("", response_model=ConversationResponse)
async def handle_conversation(
    request: ConversationRequest, 
    db: Session = Depends(get_db),
    current_user: Dict = Depends(verify_protected_token)
):
    """
    Main conversation endpoint - receives transcript and returns AI response with feedback
    """
    try:
        # Get or create user from Auth0 token
        user_id = get_or_create_user(db, current_user)
        
        openai_service = SimpleOpenAIService()
        vocabulary_service = VocabularyTierService()
        suggestion_service = SuggestionService()
        redis_service = RedisService()
        
        # Load personality and topic from session if session_id provided
        session_personality = request.personality
        if request.session_id:
            from app.models.session import Session as SessionModel
            session_row = db.query(SessionModel).filter(SessionModel.id == request.session_id).first()
            if not session_row:
                raise HTTPException(status_code=404, detail="Session not found")
            session_personality = session_personality or (session_row.personality or "friendly_neutral")
            # update last_message_at
            session_row.last_message_at = datetime.utcnow()
            db.commit()

        # Check for existing shown suggestion for usage detection
        recent_suggestion = get_most_recent_shown_suggestion(db, str(user_id))
        used_suggestion_id = None
        
        # Map minimalist personalities to existing prompt keys
        personality_map = {
            "friendly": "friendly_neutral",
            "sassy": "sassy_english",
            "blunt": "blunt_american",
        }
        effective_personality = personality_map.get(session_personality or "friendly", session_personality or "friendly_neutral")

        # Find existing conversation for this session or create new one
        conversation = None
        if request.session_id:
            # Look for existing active conversation for this session
            conversation = db.query(Conversation).filter(
                Conversation.session_id == request.session_id,
                Conversation.user_id == str(user_id),
                Conversation.status == 'active'
            ).first()
        
        if not conversation:
            # Create new conversation if none exists
            conversation_id = uuid.uuid4()
            conversation = Conversation(
                id=conversation_id,
                user_id=str(user_id),
                session_id=request.session_id,
                status='active',
                personality=effective_personality
            )
            db.add(conversation)
            db.flush()  # Get the ID without committing
        else:
            conversation_id = conversation.id
        
        # Get conversation history from Redis with database fallback (AC: 1, IV1)
        conversation_history_data = redis_service.get_conversation_history(str(conversation_id), db)
        conversation_context = redis_service.build_conversation_context(conversation_history_data)
        
        # Get suggested word for usage evaluation if available
        suggested_word = recent_suggestion.suggested_word if recent_suggestion else None
        
        # Generate enhanced coaching response with conversation history (AC: 2, 3, 4)
        coaching_response = await openai_service.generate_coaching_response(
            request.message,
            conversation_context,
            effective_personality,
            request.target_vocabulary,
            suggested_word
        )
        
        ai_response = coaching_response.ai_response
        corrected_transcript = coaching_response.corrected_transcript
        word_usage_status = coaching_response.word_usage_status
        usage_feedback = coaching_response.usage_correctness_feedback
        
        # Update suggestion status based on coaching response analysis (AC: 3)
        if recent_suggestion:
            try:
                if word_usage_status == WordUsageStatus.USED_CORRECTLY:
                    recent_suggestion.status = "used"
                    used_suggestion_id = str(recent_suggestion.id)
                    print(f"âœ… Word usage correct: '{recent_suggestion.suggested_word}' marked as used (ID: {used_suggestion_id})")
                elif word_usage_status == WordUsageStatus.USED_INCORRECTLY:
                    # Keep as "shown" but log the incorrect usage
                    print(f"âš ï¸ Word used incorrectly: '{recent_suggestion.suggested_word}' - {usage_feedback}")
                else:
                    print(f"â„¹ï¸ Word not used: '{recent_suggestion.suggested_word}'")
                
                db.add(recent_suggestion)
                db.flush()  # Ensure the update is included in transaction
            except Exception as e:
                print(f"âš ï¸ Failed to update suggestion status: {str(e)}")
                # Continue without blocking the conversation
        
        # Analyze vocabulary tier on corrected transcript for better accuracy
        tier_analysis = vocabulary_service.analyze_vocabulary_tier(corrected_transcript)
        
        # Create enhanced feedback with vocabulary tier
        feedback = {
            "clarity": 85,
            "fluency": _estimate_fluency(request.message),
            "vocabularyTier": tier_analysis.tier,
            "vocabularyScore": tier_analysis.score,
            "vocabularyUsage": [],
            "suggestions": _generate_tier_suggestions(tier_analysis),
            "overallRating": min(5, max(1, int((tier_analysis.score + _estimate_fluency(request.message)) / 25)))
        }
        
        # Vocabulary tier details for frontend
        vocabulary_tier_data = {
            "tier": tier_analysis.tier,
            "score": tier_analysis.score,
            "wordCount": tier_analysis.word_count,
            "complexWords": tier_analysis.complex_word_count,
            "averageWordLength": tier_analysis.average_word_length,
            "analysis": tier_analysis.analysis_details,
            "recommendations": vocabulary_service.get_vocabulary_recommendations(tier_analysis.tier, [])
        }
        
        # Save conversation messages to database and Redis cache
        try:
            from app.models.conversation_v2 import ConversationMessage
            
            # Save user message to database (AC: 5 - use corrected_transcript)
            user_message = ConversationMessage(
                conversation_id=conversation_id,
                role="user",
                content=corrected_transcript,  # Use corrected transcript as per AC: 5
                timestamp=datetime.utcnow()
            )
            db.add(user_message)
            db.flush()
            
            # Save AI response to database
            ai_message = ConversationMessage(
                conversation_id=conversation_id,
                role="assistant",
                content=ai_response,
                timestamp=datetime.utcnow()
            )
            db.add(ai_message)
            db.flush()
            
            # Cache messages in Redis for future conversation history (AC: 2)
            redis_service.cache_message(str(conversation_id), "user", corrected_transcript, user_message.timestamp)
            redis_service.cache_message(str(conversation_id), "assistant", ai_response, ai_message.timestamp)
            
        except Exception as e:
            print(f"âš ï¸ Message saving failed: {str(e)}")
            # Continue without blocking conversation
        
        # Generate vocabulary suggestion and save to DB
        suggestion_data = None
        try:
            suggestion = suggestion_service.generate_suggestion(request.message)
            if suggestion:
                # Save suggestion to database
                db_suggestion = VocabularySuggestion(
                    conversation_id=conversation_id,
                    user_id=str(user_id),
                    suggested_word=suggestion["word"],
                    status="shown"
                )
                db.add(db_suggestion)
                db.commit()
                db.refresh(db_suggestion)
                
                suggestion_data = {
                    "id": str(db_suggestion.id),
                    "word": suggestion["word"],
                    "definition": suggestion["definition"]
                }
        except Exception as e:
            print(f"âš ï¸ Suggestion generation failed: {str(e)}")
            # Continue without suggestion as per IV1 requirement
            # Rollback any partial transaction
            try:
                db.rollback()
            except Exception:
                pass
        
        # Create enhanced usage analysis with word usage feedback
        usage_analysis = None
        if word_usage_status != WordUsageStatus.NOT_USED:
            usage_analysis = {
                "word_usage_status": word_usage_status.value,
                "suggested_word": suggested_word,
                "usage_feedback": usage_feedback,
                "conversation_context_used": bool(conversation_context)
            }
        
        print(f"ðŸŽ¯ Original Message: {request.message}")
        print(f"âœ… Corrected Transcript: {corrected_transcript}")
        print(f"ðŸ“Š Vocabulary Tier: {tier_analysis.tier} (Score: {tier_analysis.score})")
        print(f"ðŸ¤– AI Response: {ai_response}")
        print(f"ðŸ“š Word Usage Status: {word_usage_status.value}")
        if usage_feedback:
            print(f"ðŸ’¬ Usage Feedback: {usage_feedback}")
        if used_suggestion_id:
            print(f"ðŸŽ‰ Used Suggestion ID: {used_suggestion_id}")
        if suggestion_data:
            print(f"ðŸ’¡ New Suggestion: {suggestion_data['word']} - {suggestion_data['definition']}")
        print(f"ðŸ—¨ï¸ Conversation History Length: {len(conversation_history_data)} messages")
        
        return ConversationResponse(
            response=ai_response,
            feedback=feedback,
            vocabulary_tier=vocabulary_tier_data,
            usage_analysis=usage_analysis,
            suggestion=suggestion_data,
            used_suggestion_id=used_suggestion_id
        )
        
    except Exception as e:
        print(f"âŒ Conversation Error: {str(e)}")
        raise HTTPException(status_code=500, detail=f"Conversation failed: {str(e)}")

# Add vocabulary tier analysis endpoint
@router.post("/analyze-tier")
async def analyze_vocabulary_tier(
    request: Dict, 
    db: Session = Depends(get_db),
    current_user: Dict = Depends(verify_protected_token)
):
    """Analyze vocabulary tier of provided text"""
    try:
        text = request.get("text", "")
        if not text:
            raise HTTPException(status_code=400, detail="Text is required")
        
        vocabulary_service = VocabularyTierService()
        analysis = vocabulary_service.analyze_vocabulary_tier(text)
        
        return {
            "tier": analysis.tier,
            "score": analysis.score,
            "wordCount": analysis.word_count,
            "complexWords": analysis.complex_word_count,
            "averageWordLength": analysis.average_word_length,
            "analysis": analysis.analysis_details,
            "recommendations": vocabulary_service.get_vocabulary_recommendations(analysis.tier, [])
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Analysis failed: {str(e)}")

# Legacy endpoint for backward compatibility
@router.post("/chat", response_model=ConversationResponse)
async def chat(
    request: ConversationRequest, 
    db: Session = Depends(get_db),
    current_user: Dict = Depends(verify_protected_token)
):
    return await handle_conversation(request, db, current_user)

# Get personality options
@router.get("/personalities")
async def get_personality_options():
    """Get available personality options for conversation"""
    return {
        "personalities": [
            {
                "id": "sassy_english",
                "name": "Sassy English",
                "description": "Witty and playful with a charming British flair",
                "example_response": "Oh brilliant! That's quite fascinating, isn't it?"
            },
            {
                "id": "blunt_american",
                "name": "Blunt American", 
                "description": "Direct and no-nonsense, but supportive",
                "example_response": "Alright, let's get straight to the point here."
            },
            {
                "id": "friendly_neutral",
                "name": "Friendly Neutral",
                "description": "Warm and encouraging conversation partner",
                "example_response": "That's wonderful! I'd love to hear more about that."
            }
        ]
    }

# Get welcome message for first-time users
@router.get("/welcome")
async def get_welcome_message(personality: str = "friendly_neutral", db: Session = Depends(get_db)):
    """Get personalized welcome message for first-time users"""
    try:
        openai_service = SimpleOpenAIService()
        welcome_message = await openai_service.generate_welcome_message(personality)
        
        return {
            "message": welcome_message,
            "personality": personality,
            "isWelcome": True
        }
    except Exception as e:
        print(f"âŒ Welcome Message Error: {str(e)}")
        # Fallback welcome messages
        fallback_messages = {
            "sassy_english": "Well hello there! Welcome to ImprovToday, darling! What name shall I call you, and do tell me - how's your day been?",
            "blunt_american": "Hey there, welcome to ImprovToday! What should I call you, and how was your day?",
            "friendly_neutral": "Welcome to ImprovToday! I'm so glad you're here. What name should I address you with? How has your day been?"
        }
        
        return {
            "message": fallback_messages.get(personality, fallback_messages["friendly_neutral"]),
            "personality": personality,
            "isWelcome": True
        }

@router.get("/history")
async def get_conversation_history(
    db: Session = Depends(get_db),
    current_user: Dict = Depends(verify_protected_token)
):
    # Get user and return their conversation history
    user_id = get_or_create_user(db, current_user)
    return {"conversations": [], "user_id": user_id}

def _estimate_fluency(transcript: str) -> int:
    """Estimate fluency based on transcript characteristics"""
    words = transcript.split()
    word_count = len(words)
    avg_word_length = sum(len(word) for word in words) / len(words) if words else 0
    
    # Simple heuristic scoring
    base_score = 70
    if word_count > 5: base_score += 10
    if word_count > 10: base_score += 5
    if avg_word_length > 4: base_score += 10
    
    return min(100, base_score)

def _generate_tier_suggestions(tier_analysis) -> List[str]:
    """Generate suggestions based on vocabulary tier analysis"""
    suggestions = []
    
    if tier_analysis.tier == "basic":
        suggestions.extend([
            "Try using more descriptive words instead of 'good', 'bad', or 'nice'",
            "Consider expanding your sentences with more details",
            "Practice using words with more than 4-5 letters"
        ])
    elif tier_analysis.tier == "mid":
        suggestions.extend([
            "Great vocabulary variety! Try incorporating more advanced words",
            "Your word choice shows good progression",
            "Consider using more sophisticated synonyms"
        ])
    else:  # top
        suggestions.extend([
            "Excellent vocabulary sophistication!",
            "Your word choice demonstrates advanced language skills",
            "Keep up the great use of complex vocabulary"
        ])
    
    # Add word count specific suggestions
    if tier_analysis.word_count < 10:
        suggestions.append("Try expressing your thoughts in more detail")
    elif tier_analysis.word_count > 50:
        suggestions.append("Great detailed response! Practice being concise too")
    
    return suggestions[:3]  # Return top 3 suggestions